# C++ to Python Converter Configuration
# Copy this file to .env and update the values

# OpenAI-compatible API URL
# Examples:
# - Ollama: http://localhost:11434/v1
# - OpenAI: https://api.openai.com/v1
# - LocalAI: http://localhost:8080/v1
LLM_API_URL=http://localhost:11434/v1

# API Key (use 'ollama' for Ollama, your actual key for OpenAI)
# For multiple keys (to increase RPM), separate with commas:
# LLM_API_KEY=key1,key2,key3
LLM_API_KEY=ollama

# Model name
# Examples:
# - Ollama: llama2, codellama, mistral
# - OpenAI: gpt-3.5-turbo, gpt-4
# - LocalAI: depends on your deployed models
LLM_MODEL=llama2